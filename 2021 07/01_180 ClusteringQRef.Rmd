---
title: "Clustering in R Quick Reference"
author: "Mark Niemann-Ross"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
    toc: yes
  github_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(cluster)

```


# About
## About This Document

This document provides brief explanations of the clustering functions available in Base R and the cluster package. 

## Related Material
[The cluster package](https://cran.r-project.org/web/packages/cluster/index.html) is recommended for advanced operations. The cluster package is based on [Finding Groups in Data](https://onlinelibrary.wiley.com/doi/book/10.1002/9780470316801) 

An exhaustive discussion of clustering can be found at [Machine Learning and AI foundations:clustering and association](https://linkedin-learning.pxf.io/lilclustering)

This Quick Reference is supplemental to courses on [LinkedIn Learning](https://www.linkedin.com/learning/r-for-data-science-lunchbreak-lessons/). A quick reference to [matrix math functions in R is here](http://niemannross.com/link/rmatrixqref). A quick reference to [plotting functions in R is here](http://niemannross.com/link/rplotqref). An index to all R functions covered at LinkedIn Learning is found [here](http://niemannross.com/link/rindex). The latest version of this quick reference is found [here](http://niemannross.com/link/rclusterqref). The source to this document is found on [github/mnr](https://github.com/mnr/R-for-Data-Science-Lunchbreak-Lessons). This document is available as Free Software under the terms of the [Free Software Foundationâ€™s](http://www.gnu.org/) [GNU General Public License](https://www.r-project.org/COPYING).

## About Mark Niemann-Ross
[Mark](https://niemannross.com/) is an author for LinkedIn Learning and writes Science Fiction.

# Partitioning methods
Divide dataset into k clusters. (k is defined by researcher)

## *kmeans* : Partitioning around centroids

```{r, echo=TRUE}

# kmeans clusters data together, based on average distance from a centroid
# kmeans iterates through possible solutions to identify the best result

kmeans(quakes, 3)

# lots of information in the print from kmeans
# cluster sizes
# cl$centers - cluster means - shows the centroid for each cluster
# cl$cluster - clustering vector - shows which data points belong to which cluster
# cl$withinss - within cluster sum of squares - small SofS = more compact cluster


cl <- kmeans(quakes, 3)
plot(quakes, col = cl$cluster)
# what are we looking at.

#simplify
simpleQuakes <- quakes[,c("long","lat")]
cl <- kmeans(simpleQuakes, 4)
plot(simpleQuakes, col = cl$cluster)



```


## *pam* : Partitioning Around Medoids

```{r, echo=TRUE}
simpleQuakes <- quakes[,c("long","lat")]
mypam <- pam(simpleQuakes,2) # assuming 2 medoids

# components of mypam - see pam.object
# for example...
mypam$medoids # coordinates of medoids
mypam$id.med # indices of medoids (i.e. simpleQuakes[mypam$id.med,])

# mypam$clustering # which points belong to which medoid
# same as... pam(simpleQuakes, 4, cluster.only = TRUE)


# plotting PAM
#plot(mypam)
#plot(mypam, ask = TRUE) # menu for plots

#map("worldHires","Fiji", xlim=c(160,190), ylim =c(-40,-15))
plot(mypam, which.plots = 1)

```

## *clara* : Clustering Large Applications
Clara is identical to pam() except subsamples the data before determining medoids.

```{r, echo=TRUE}
myclara <- clara(quakes,2)
plot(myclara, which.plots = 1) #graph
plot(myclara, which.plots = 2) #silhoutte

```


## *fanny* : Fuzzy Analysis Clustering
```{r, echo=TRUE}
# downsample quakes for demonstration. from 500 to 25
simpleQuakes <- quakes[sample(nrow(quakes),25),c("long","lat")]

# create a fuzzy cluster with fanny
fuzCluster <- fanny(x = simpleQuakes, k = 3) 
fuzCluster

# this produces 4 parts: object, membership, fuzzyness, other components of object
fuzCluster$membership # percentage likelihood this point is part of this cluster. 
fuzCluster$coeff # A low value of Dunn's coefficient indicates a very fuzzy clustering, whereas a value close to 1 indicates a near-crisp clustering
fuzCluster$clustering # closest hard/crisp cluster

```


# Hierarchical methods
Start with cluster of one item, then build larger clusters (or the opposite)


## *hclust* : Hierarchical Clustering

```{r, echo=TRUE}
# builds a dendogram

# what is a distance matrix? (distance between points)
sampleQuakes <- quakes[sample(1:length(quakes$lat), 5),] # demonstrate a small set
sampleQuakes # here's the data
dist(sampleQuakes) # here's the distance matrix

# now here's a hierarchical cluster
hclust(dist(quakes)) # returns an hclust object

plot(hclust(dist(quakes))) # overplot
plot(hclust(dist(sampleQuakes))) # more approachable
# starts with one cluster per element
# Progressing up dendrogram produces larger clusters until one cluster at top
# Labels are row numbers. 
plot(hclust(dist(sampleQuakes)),
     labels = c(LETTERS[1:length(sampleQuakes)])) # labeled points
rect.hclust(hclust(dist(sampleQuakes)), k=2) # draw box around clusters

```

## cutree: produce cluster from hierarchical
```{r, echo=TRUE}
# cutree produces clusters from hclust objects
cutree(hclust(dist(sampleQuakes)),k=2)

```


## *agnes* : Agglomerative Nesting

Agnes is a heirarchical method. It's like hclust, but includes an agglomerative coefficient and banner plot. Agnes produces hclust objects and works with hclust functions. It sometimes requires as.hclust(). Unlike hclust, agnes doesn't require dist().

agglomerative means start with clusers of n=1, then increase n

```{r, echo=TRUE}

agnes(quakes)

# downsample quakes for demonstration. from 500 to 25
simpleQuakes <- quakes[sample(nrow(quakes),25),c("long","lat")]

plot(agnes(simpleQuakes), which.plots = 1) # banner plot
plot(agnes(simpleQuakes), which.plots = 2) # dendogram

# methods provided by agnes
plot(agnes(simpleQuakes, method = "average"), which.plots = 2) 
plot(agnes(simpleQuakes, method = "single"), which.plots = 2) 
plot(agnes(simpleQuakes, method = "complete"), which.plots = 2) 
plot(agnes(simpleQuakes, method = "ward"), which.plots = 2) 
plot(agnes(simpleQuakes, method = "weighted"), which.plots = 2) 
plot(agnes(simpleQuakes, method = "flexible", par.method = 4), which.plots = 2) 


```


## *diana* : DIvisive ANAlysis Clustering

## *mona* : MONothetic Analysis Clustering of Binary Variables

MONothetic analysis clustering of binary variables. Divisive (instead of Agglomerative). Focused on binary datasets

```{r, echo=TRUE}

# Titanic has three binary attributes

# convert titanic dataset from array to data.frame
#https://stackoverflow.com/questions/59447399/how-to-transform-the-titanic-data-set
d1 <- as.data.frame(Titanic)
Tita <- d1[rep(seq_len(nrow(d1)), d1$Freq),1:4]
row.names(Tita) <- NULL

# downsample for this example
smallTitanic <- Tita[sample(nrow(Tita), 30),
                     c("Sex","Age","Survived")]


monaTitanic <- mona(smallTitanic)
monaTitanic

plot(monaTitanic) # only bannerplot is available

# examine mona object
data.frame("order"=monaTitanic$order,
           "Row Number"=monaTitanic$order.lab,
           "Split Variable"=c(monaTitanic$variable,"NULL"),
           "Step Level"=c(monaTitanic$step,"0")
)

```


# Dissimilarity

## *daisy* and *dist* : Dissimilarity Matrix Calculation

daisy and dist create a dissimilarity matrix.

daisy - dissimilarity on multiple data types - performs Dissimilarity Matrix Calculation. daisy returns a dissimilarity.object


dist - dissimilarity on numeric variables - performs Distance Matrix calculation. dist returns a dist object


```{r, echo=TRUE}

# downsample quakes for demonstration. from 500 to 25
simpleQuakes <- quakes[sample(nrow(quakes),5),]

# all values are numeric, so these return the same values
daisy(simpleQuakes)
dist(simpleQuakes)

# but...add a binary TRUE/FALSE column
binaryVector <- sample(c(FALSE,TRUE), nrow(simpleQuakes), replace = TRUE) 
mixedSimpQuake <- cbind(simpleQuakes, binaryVector)

# now there are significant differences
daisy(mixedSimpQuake) # includes TF column in calculation
dist(mixedSimpQuake) # ignores the TF column, same values as above

# daisy can be used in place of dist
plot(hclust(dist(mixedSimpQuake)))
plot(hclust(daisy(mixedSimpQuake)))

plot(agnes(daisy(mixedSimpQuake)), which.plots = 2)

```

# Graphics and Plots

## clusplot

## silhouette
```{r, echo=TRUE}
# cluster functions provide the silhouette graph
# silhouette measures the quality of the cluster
# A high average silhouette width indicates a good clustering

simpleQuakes <- quakes[sample(nrow(quakes),25),c("long","lat")]

silhouette(pam(simpleQuakes, 3))
# returns assigned cluster, neighbor cluster, width from this point to neighboring cluster
# large sil_width is better cluster
# Observations with a large Si (almost 1) are very well clustered, 
# a small  (around 0) means that the observation lies between two clusters, 
# and observations with a negative  are probably placed in the wrong cluster.

summary(silhouette(pam(simpleQuakes, 3)))
# provides useful information
summary(silhouette(pam(quakes, 2))) # median width is indicator of quality related to k


#plotting
plot(pam(simpleQuakes,4), which.plots = 2) 
# notice negative value
# what is average silhouette width? (larger is better)

plot(pam(simpleQuakes,2), which.plots = 2) 
# now what is average?

# clusplot
plot(pam(simpleQuakes,4), which.plots = 1) 
plot(pam(simpleQuakes,2), which.plots = 1) 

# overplotting
plot(pam(quakes,2), which.plots = 2)
plot(clara(quakes,2), which.plots = 2) # clara does subsampling

```




